# -*- coding: utf-8 -*-
"""
Created on Wed Aug 20 18:54:49 2025

@author: camic

Este c√≥digo desarrolla una simulaci√≥n simple de un robot en una grilla 2x2,
aplicando los conceptos de:
- Estado
- Espacio de estados
- Acciones
- Recompensa
- Ambiente

Adem√°s, cumple con los 4 puntos solicitados en la tarea:

1. Modificar la funci√≥n mover_robot para que la bater√≠a baje en cada movimiento.
2. Si la bater√≠a llega a 0, el robot no se puede mover hasta recargar.
3. A√±adir m√°s recompensas o castigos (intentar moverse sin bater√≠a, bonus por llegar r√°pido, etc).
4. Probar diferentes estrategias de movimiento para maximizar la recompensa.
"""

# ========================
# 1. VARIABLES DE ESTADO
# ========================
# El estado inicial del robot incluye:
# - posici√≥n en la grilla (0,0)
# - nivel de bater√≠a (50)
# - si alcanz√≥ o no el objetivo (False)
estado_robot = {
    "posicion": (0, 0),
    "bateria": 50,
    "objetivo_alcanzado": False
}

print("Estado inicial del robot:", estado_robot)

# ========================
# 2. ESPACIO DE ESTADOS
# ========================
# El espacio de estados es el conjunto de todas las combinaciones
# posibles de posiciones y niveles de bater√≠a (simplificado en "alta" o "baja").
posiciones = [(x, y) for x in range(3) for y in range(3)]
baterias = ["alta", "baja"]

espacio_estados = [(p, b) for p in posiciones for b in baterias]
print("\nTotal de estados posibles:", len(espacio_estados))
print("Ejemplos de estados:", espacio_estados[:5])

# ========================
# 3. ESPACIO DE ACCIONES
# ========================
# El robot puede moverse en las 4 direcciones b√°sicas o recargar su bater√≠a.
acciones = ["adelante", "atras", "izquierda", "derecha", "recargar"]
print("\nAcciones posibles:", acciones)

# ========================
# 4. FUNCI√ìN DE RECOMPENSA
# ========================
# Aqu√≠ se definen las recompensas y castigos que recibe el robot
# dependiendo de la acci√≥n tomada y el estado alcanzado.
def recompensa(accion, nuevo_estado, paso):
    # Recompensa por recargar
    if accion == "recargar":
        return 5
    
    # Castigo por intentar moverse sin bater√≠a
    if accion in ["adelante", "atras", "izquierda", "derecha"] and nuevo_estado["bateria"] == 0 and not nuevo_estado["objetivo_alcanzado"]:
        return -5  

    # Recompensa por alcanzar el objetivo
    if nuevo_estado["objetivo_alcanzado"]:
        if paso < 5:  # Bonus por hacerlo r√°pido
            return 30  
        else:
            return 10  
    
    # Costo de cada movimiento normal
    if accion in ["adelante", "atras", "izquierda", "derecha"]:
        return -1  
    
    return 0

# ========================
# 5. AMBIENTE Y SIMULACI√ìN
# ========================
# Esta funci√≥n describe c√≥mo el ambiente responde a las acciones del robot.
def mover_robot(estado, accion):
    x, y = estado["posicion"]

    if accion in ["adelante", "atras", "derecha", "izquierda"]:
        # SOLO se mueve si tiene bater√≠a
        if estado["bateria"] > 0:
            if accion == "adelante":
                x = min(x + 1, 2)
            elif accion == "atras":
                x = max(x - 1, 0)
            elif accion == "derecha":
                y = min(y + 1, 2)
            elif accion == "izquierda":
                y = max(y - 1, 0)
            
            # La bater√≠a baja 10 unidades por cada movimiento (PUNTO 1)
            estado["bateria"] = max(estado["bateria"] - 10, 0)
        else:
            # Si no tiene bater√≠a, no se mueve (PUNTO 2)
            print("‚ö†Ô∏è BATERIA AGOTADA, POR FAVOR RECARGA")

    elif accion == "recargar":
        # Acci√≥n de recarga, devuelve bater√≠a al 100
        estado["bateria"] = 100

    # Se actualiza la posici√≥n
    estado["posicion"] = (x, y)

    # Si llega a (2, 2), se considera objetivo alcanzado
    if estado["posicion"] == (2, 2):
        estado["objetivo_alcanzado"] = True

    return estado

# ========================
# 6. SIMULACI√ìN DEL ROBOT (MANUAL)
# ========================
# Aqu√≠ se permite al usuario controlar el robot manualmente.
# La recompensa total se acumula seg√∫n las reglas definidas.
estado = {"posicion": (0, 0), "bateria": 50, "objetivo_alcanzado": False}
recompensa_total = 0

print("\n=== SIMULACI√ìN DEL ROBOT (MODO MANUAL) ===")
for paso in range(10):  # Se limita a 10 pasos
    print("\nEstado actual:", estado)
    accion = input("Elige una acci√≥n (adelante, atras, izquierda, derecha, recargar): ")

    # Normalizamos la entrada
    accion = accion.strip().lower()

    if accion not in acciones:
        print("‚ö†Ô∏è Acci√≥n no v√°lida, intenta de nuevo.")
        continue

    # Se actualiza el estado con la acci√≥n elegida
    estado = mover_robot(estado, accion)

    # Se calcula la recompensa correspondiente
    r = recompensa(accion, estado, paso)
    recompensa_total += r

    print(f"Paso {paso+1}: Acci√≥n = {accion}, Estado = {estado}, Recompensa = {r}")

    # Si el robot llega a la meta, se termina la simulaci√≥n
    if estado["objetivo_alcanzado"]:
        print("üéâ ¬°Objetivo alcanzado!")
        break

# Al final se muestra la recompensa acumulada
print("\n‚úÖ Recompensa total obtenida:", recompensa_total)

